{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-uXkEHsUyO1"
      },
      "source": [
        "# Assignment 3 (due Oct 30th at 11:59pm)\n",
        "\n",
        "- This assignment covers Linear Regression, Model Selection, and Regularization. Please refer to the class notes and corresponding Colabs on the course website for the required background.\n",
        "\n",
        "- The assignment requires that you participate of Kaggle Competitions.  We created a private competition that must be accessed via this [invitation link](https://www.kaggle.com/t/678a70d78f624f39b88d30184fe98e8b).\n",
        "\n",
        "- This assignment is worth **100 points**.  After completing the solutions you will submit a copy of this notebook (`.ipynb`), including all your answers.\n",
        "\n",
        "- You are free to use any Python library.\n",
        "\n",
        ">  **Important**: Make sure all cells are executed before saving/downloading a copy of the notebook you will submit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJLqXw_EU6ip"
      },
      "source": [
        "## Question 1 (5 points)\n",
        "Load the data files available at the [Kaggle competition](https://www.kaggle.com/competitions/uri-ml-hw-3-f22) created for this assignent.  Print the shapes of all matrices/objects you are creating.  Can use `pandas` or `numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hLMBr3GvU9D6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_x shape:  (14447, 9) \n",
            "train_y shape:  (14447, 2) \n",
            "test_x shape:  (6193, 9)\n"
          ]
        }
      ],
      "source": [
        "# your answer here \n",
        "train_x = pd.read_csv(\"uri-ml-hw-3-f22/trainx.csv\")\n",
        "train_y = pd.read_csv(\"uri-ml-hw-3-f22/trainy.csv\")\n",
        "test_x = pd.read_csv(\"uri-ml-hw-3-f22/testx.csv\")\n",
        "\n",
        "print(\"train_x shape: \",train_x.shape, \"\\ntrain_y shape: \", train_y.shape, \"\\ntest_x shape: \", test_x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"train_x first few: \\n\", train_x.head(), \"\\ntrain_y first few: \\n\", train_y.head(), \"\\ntest_x first few: \\n\", test_x.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD1ynma5keSG"
      },
      "source": [
        "## Question 2 (10 points)\n",
        "Print the `min` and `max` values for all input features in the training data and the test data.  It will give you a rough idea of ranges on each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VR3KYHSpkle7"
      },
      "outputs": [],
      "source": [
        "# your answer here\n",
        "print(\"Max in each feature of train_x: \\n\", train_x.max(), \"\\nMin in each feature of train_x: \\n\", train_x.min())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Max in each feature of test_x: \\n\", test_x.max(), \"\\nMin in each feature of test_x: \\n\", test_x.min())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vFPYU-ZZD7q"
      },
      "source": [
        "## Question 3 (75 pts)\n",
        "Here you will perform model selection, testing a number of different configurations for a final model.\n",
        "\n",
        "- play with regularization methods.  You are expected to try plain Linear Regression, and Linear Regression with L1/L2 regularization.  You can use the code provided in class or rely on `scikit-learn` implementations.  20 points are awarded for a correct use of all three methods.\n",
        "\n",
        "- apply different pre-processing techniques.  30 points are awarded here for a correct pre-processing.  We expect you to preprocess your data with the following strategies:\n",
        "\n",
        "    - normalization or scaling (e.g. `StandardScaler`, `MinMaxScaler`, `RobustScaler`)\n",
        "    - feature transformations (e.g. `PolynomialFeatures`, applying functions like `log`, or both)\n",
        "    - PCA after feature transformations\n",
        "\n",
        "> Hint: most of the transformations require you to `fit` to the training data first and then `transform` the test data.  Please read the documentation of every transformation you intend to apply.  Alternatively, a `Pipeline` is extremely useful.  Examples can be found at [Pipelines and composite estimators](https://scikit-learn.org/stable/modules/compose.html).\n",
        "\n",
        "- model selection must use **cross-validation**. You can use any of the functions provided in scikit-learn (e.g. `cross_val_score`, `train_test_split`).  Here is a good introduction to their usage: [Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html).  25 points are awarded for a correct use of CV.\n",
        "\n",
        "> Hint: if you dont want to implement your own cross-validation loop, there is a `GridSearchCV` object that can help in the process.  Documentation is available at [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_df = pd.DataFrame(test_x.Id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14451</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id\n",
              "0  14447\n",
              "1  14448\n",
              "2  14449\n",
              "3  14450\n",
              "4  14451"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x = train_x.drop(columns = 'Id')\n",
        "train_y = train_y.drop(columns = 'Id')\n",
        "test_x = test_x.drop(columns = 'Id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x = train_x.to_numpy()\n",
        "train_y = train_y.to_numpy()\n",
        "test_x = test_x.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# First Model \n",
        "#### Regular Linear Regression with Robust Scaler and PolynomialFeatures == 2 and PCA with cutoff at 95%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_pipe = Pipeline([\n",
        "    ('robust_scaler', preprocessing.RobustScaler()), \n",
        "    ('polynomailfeatures', preprocessing.PolynomialFeatures(2)), \n",
        "    ('PCA', PCA(n_components = 0.95)), \n",
        "    ('Linear Regression', linear_model.LinearRegression())\n",
        "]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-117288.67078766 -115115.13734309 -116447.86119489 -116808.56526957\n",
            " -112748.9515617  -115295.6363525  -113316.68318298 -114169.04216358\n",
            " -113450.38820082 -113428.22562681]\n"
          ]
        }
      ],
      "source": [
        "print(cross_val_score(lr_pipe, train_x, train_y, cv=10, scoring = 'neg_root_mean_squared_error'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Second Model\n",
        "#### L2 Regression with Robust Scaler and PolynomialFeatures == 2 and PCA with cutoff at 95%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "L2_pipe = Pipeline(steps = [\n",
        "    ('robust_scaler', preprocessing.RobustScaler()),\n",
        "    ('PolynomialFeatures', preprocessing.PolynomialFeatures(2)),\n",
        "    ('PCA', PCA(n_components= .95)),\n",
        "    ('L2 Regression', linear_model.Ridge(alpha = .0001))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[116120.731404   116639.11289825 114012.7648224  113709.40173904\n",
            " 113420.60664128]\n"
          ]
        }
      ],
      "source": [
        "print(-1 * (cross_val_score(L2_pipe, train_x, train_y, cv = 5, scoring = 'neg_root_mean_squared_error')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "L2_pipe.fit(train_x, train_y)\n",
        "L2_preds = L2_pipe.predict(test_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Third Model\n",
        "#### L1 Regression with Robust Scaler and PolynomalFeatures == 2 and PCA with cutoff at 95%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "L1_pipe = Pipeline(steps = [\n",
        "    ('robust_scaler', preprocessing.RobustScaler()), \n",
        "    ('PolynomaialFeatures', preprocessing.PolynomialFeatures(2)),\n",
        "    ('PCA', PCA(n_components = .95)),\n",
        "    ('L1 Regression', linear_model.Lasso(alpha = .0001))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[116120.73139847 116639.11289839 114012.76482262 113709.40173961\n",
            " 113420.60664133]\n"
          ]
        }
      ],
      "source": [
        "print(-1 * (cross_val_score(L1_pipe, train_x, train_y, cv = 5, scoring = 'neg_root_mean_squared_error')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fourth Model\n",
        "#### L2 Regression with Grid Search on alpha values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ridge_param_grid = [{\n",
        "    'L2_Regression__alpha': [.1, .01, .001, .0001]\n",
        "    }]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "Ridge_pipe = Pipeline([\n",
        "    ('robust_scaler', preprocessing.RobustScaler()),\n",
        "    ('PCA', PCA(n_components = .95)),\n",
        "    ('L2_Regression', linear_model.Ridge())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'L2_Regression__alpha': 0.0001}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_pipeline = GridSearchCV(Ridge_pipe, param_grid = ridge_param_grid, scoring = 'neg_root_mean_squared_error', cv = 5)\n",
        "grid_pipeline.fit(train_x, train_y)\n",
        "grid_pipeline.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[78654.98985389 80821.91585767 84300.18617634 80953.29873881\n",
            " 81254.75254439]\n"
          ]
        }
      ],
      "source": [
        "print(-1 * (cross_val_score(grid_pipeline.best_estimator_, train_x, train_y, cv = 5, scoring = 'neg_root_mean_squared_error')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fifth Model\n",
        "#### L2 regression with multiple PolynomialFeature Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Degree 2 RSME:\n",
            "[116120.73075934 116639.11290486 114012.76483189 113709.40179307\n",
            " 113420.60664441]\n",
            "\n",
            "Degree 3 RSME:\n",
            "[116120.73075934 116639.11290486 114012.76483189 113709.40179307\n",
            " 113420.60664441]\n",
            "\n",
            "Degree 4 RSME:\n",
            "[116120.73075934 116639.11290486 114012.76483189 113709.40179307\n",
            " 113420.60664441]\n",
            "\n",
            "Degree 5 RSME:\n",
            "[116120.73075934 116639.11290486 114012.76483189 113709.40179307\n",
            " 113420.60664441]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "degrees = [2, 3, 4, 5]\n",
        "\n",
        "for degree in degrees:\n",
        "\n",
        "    Ridge_pipe = Pipeline([\n",
        "    ('robust_scaler', preprocessing.RobustScaler()),\n",
        "    ('polynomialfeatures', preprocessing.PolynomialFeatures(degree = 2)),\n",
        "    ('PCA', PCA(n_components = .95, svd_solver = 'full')),\n",
        "    ('L2_Regression', linear_model.Ridge())\n",
        "    ])\n",
        "    grid_pipeline = GridSearchCV(Ridge_pipe, param_grid = ridge_param_grid, scoring = 'neg_root_mean_squared_error', cv = 5)\n",
        "    grid_pipeline.fit(train_x, train_y)\n",
        "    \n",
        "    print(\"Degree {} RSME:\\n{}\\n\".format(degree, -1 * (cross_val_score(grid_pipeline.best_estimator_, train_x, train_y, cv = 5, scoring = 'neg_root_mean_squared_error'))))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Components 8 RSME:\n",
            "[ 97563.0062469   99796.77529005 102170.99275965  99637.82593767\n",
            "  99189.15623352]\n",
            "\n",
            "Components 16 RSME:\n",
            "[78067.25760645 79588.31378497 82817.09587501 78742.93592669\n",
            " 79659.89942199]\n",
            "\n",
            "Components 32 RSME:\n",
            "[87320.52843385 69711.27933077 72583.39050994 68313.80831689\n",
            " 67164.10828465]\n",
            "\n",
            "Components 40 RSME:\n",
            "[73594.48634389 66164.77660127 68132.54391928 63739.99819964\n",
            " 63333.37430625]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "components = [8, 16, 32, 40]\n",
        "\n",
        "for component in components:\n",
        "\n",
        "    Ridge_pipe = Pipeline([\n",
        "    ('robust_scaler', preprocessing.RobustScaler()),\n",
        "    ('polynomialfeatures', preprocessing.PolynomialFeatures(degree = 2)),\n",
        "    ('PCA', PCA(n_components = component)),\n",
        "    ('L2_Regression', linear_model.Ridge())\n",
        "    ])\n",
        "    grid_pipeline = GridSearchCV(Ridge_pipe, param_grid = ridge_param_grid, scoring = 'neg_root_mean_squared_error', cv = 5)\n",
        "    grid_pipeline.fit(train_x, train_y)\n",
        "    \n",
        "    print(\"Components {} RSME:\\n{}\\n\".format(component, -1 * (cross_val_score(grid_pipeline.best_estimator_, train_x, train_y, cv = 5, scoring = 'neg_root_mean_squared_error'))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross validation cv = 5 RMSE:\n",
            "[73594.48634389 66164.77660127 68132.54391928 63739.99819964\n",
            " 63333.37430625]\n"
          ]
        }
      ],
      "source": [
        "Ridge_pipe = Pipeline([\n",
        "('robust_scaler', preprocessing.RobustScaler()),\n",
        "('polynomialfeatures', preprocessing.PolynomialFeatures(degree = 2)),\n",
        "('PCA', PCA(n_components = 40)),\n",
        "('L2_Regression', linear_model.Ridge())\n",
        "])\n",
        "grid_pipeline = GridSearchCV(Ridge_pipe, param_grid = ridge_param_grid, scoring = 'neg_root_mean_squared_error', cv = 5)\n",
        "grid_pipeline.fit(train_x, train_y)\n",
        "    \n",
        "print(\"Cross validation cv = 5 RMSE:\\n{}\".format(-1 * (cross_val_score(grid_pipeline.best_estimator_, train_x, train_y, cv = 5, scoring = 'neg_root_mean_squared_error'))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "curr_best_model = grid_pipeline.best_estimator_\n",
        "bm_preds = curr_best_model.predict(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14447</td>\n",
              "      <td>293112.944793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14448</td>\n",
              "      <td>217759.024055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14449</td>\n",
              "      <td>397950.619326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14450</td>\n",
              "      <td>379451.980303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14451</td>\n",
              "      <td>139152.207208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id      Predicted\n",
              "0  14447  293112.944793\n",
              "1  14448  217759.024055\n",
              "2  14449  397950.619326\n",
              "3  14450  379451.980303\n",
              "4  14451  139152.207208"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_df['Predicted'] = bm_preds\n",
        "output_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_df.to_csv(\"best_model.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCLQtfLPlynG"
      },
      "source": [
        "## Question 4 (10 pts)\n",
        "Include a description of your best solution, your place in the leaderboard, and public/private scores from the [Kaggle competition](https://www.kaggle.com/competitions/uri-ml-hw-3-f22).  You will only get points if your scores are above the Linear Regression baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Answer\n",
        "Currently, my position on the leaderboard is 2. I have beaten L1 regression and the random baseline, but have not optimized my L2 model enough to beat the L2 regression baseline. My model currently uses Ridge Regression (L2 Regression) with an alpha value of .0001. My preprocessing includes using RobustScaler, but I might change it to MinMaxScaler after seeing promising results after trying optimize a different model I tried building. I then perform PolynomialFeatures with degree of 2 after testing multiple degrees but discovered that it didn't really help (I am open to trying it again with different combinations in GridSearchCV). I then perform PCA with 40 Principal Components because I found that this was the right number of components after thouroughly testing a plethora of PCs. After that I perform grid search on different alpha values for the L2 regressor and create a \"best model\" with the best alpha value.   "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "da2656c9e6c6bdafe71e1d77f094e6d700f8e721ce962638229309038a08fa06"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
